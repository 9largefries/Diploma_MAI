{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регрессия RUL различными методами\n",
    "\n",
    "TO DO:\n",
    "- LogisticRegression\n",
    "- Random Forest \n",
    "- Gradient Boosting (sklearn, catboost, xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import gridspec\n",
    "from PIL import Image\n",
    "import itertools\n",
    "from time import time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_array\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from tensorflow import GradientTape\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/train_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet('data/test_data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отшкалируем данные и удалим наны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = ['setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
    "#        's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
    "#        's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "\n",
    "params = ['setting1', 'setting2', 's2', 's3', 's4', 's7', \n",
    "          's8', 's9', 's11', 's12', 's13', 's14', 's15', 's17', \n",
    "          's20', 's21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df[params] = scaler.fit_transform(df[params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[params] = scaler.fit_transform(test[params])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация последовательностей с окном 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_generator(data, seq_len, seq_cols):\n",
    "    \n",
    "    dt = data[seq_cols].values\n",
    "    num_elem = dt.shape[0]\n",
    "    for start, stop in zip(range(0, num_elem-seq_len), range(seq_len, num_elem)):\n",
    "        yield df[start:stop, :]\n",
    "        \n",
    "def gen_labels(data, seq_len, label):\n",
    "    \n",
    "    dt = data[seq_cols].values\n",
    "    num_elem = dt.shape[0]\n",
    "    return dt[seq_len:num_elem, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sequence(id_df, seq_length, seq_cols):\n",
    "\n",
    "    data_matrix = id_df[seq_cols].values\n",
    "    num_elements = data_matrix.shape[0]\n",
    "    # Iterate over two lists in parallel.\n",
    "    # For example id1 have 192 rows and sequence_length is equal to 50\n",
    "    # so zip iterate over two following list of numbers (0,142),(50,192)\n",
    "    # 0 50 (start stop) -> from row 0 to row 50\n",
    "    # 1 51 (start stop) -> from row 1 to row 51\n",
    "    # 2 52 (start stop) -> from row 2 to row 52\n",
    "    # ...\n",
    "    # 141 191 (start stop) -> from row 141 to 191\n",
    "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
    "        yield data_matrix[start:stop, :]\n",
    "        \n",
    "def gen_labels(id_df, seq_length, label):\n",
    "\n",
    "    data_matrix = id_df[label].values\n",
    "    num_elements = data_matrix.shape[0]\n",
    "    # I have to remove the first seq_length labels\n",
    "    # because for one id the first sequence of seq_length size have as target\n",
    "    # the last label (the previus ones are discarded).\n",
    "    # All the next id's sequences will have associated step by step one label as target.\n",
    "    return data_matrix[seq_length:num_elements, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain shape: (15631, 50, 16),\n",
      "Xtest shape: (8162, 50, 16)\n"
     ]
    }
   ],
   "source": [
    "xtrain, xtest = [], []\n",
    "\n",
    "seq_len = 50\n",
    "\n",
    "for eid in df.id.unique():\n",
    "    for seq in gen_sequence(df[df.id==eid], seq_len, params):\n",
    "        xtrain.append(seq)\n",
    "    for seq in gen_sequence(test[test.id==eid], seq_len, params):\n",
    "        xtest.append(seq)\n",
    "        \n",
    "xtrain = np.asarray(xtrain)\n",
    "xtest = np.asarray(xtest)\n",
    "\n",
    "print('Xtrain shape: {},\\nXtest shape: {}'.format(xtrain.shape, xtest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ytrain shape: (15631, 1),\n",
      "Ytest shape: (8162, 1)\n"
     ]
    }
   ],
   "source": [
    "ytrain, ytest = [],[]\n",
    "\n",
    "for eid in df.id.unique():\n",
    "    for label in gen_labels(df[df.id==eid], seq_len, ['RUL']):\n",
    "        ytrain.append(label)\n",
    "    for label in gen_labels(test[test.id==eid], seq_len, ['RUL']):\n",
    "        ytest.append(label)\n",
    "        \n",
    "ytrain = np.asarray(ytrain).reshape(-1,1)\n",
    "ytest = np.asarray(ytest).reshape(-1,1)\n",
    "\n",
    "print('Ytrain shape: {},\\nYtest shape: {}'.format(ytrain.shape, ytest.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Рекуррентные нейронные сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 50, 64)            20736     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 50, 64)            256       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 54,337\n",
      "Trainable params: 54,081\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=64,\n",
    "                input_shape = (seq_len, len(params)),\n",
    "               activation='tanh', \n",
    "               recurrent_activation='hard_sigmoid',\n",
    "               return_sequences = True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(64,\n",
    "              activation='tanh', \n",
    "               recurrent_activation='hard_sigmoid'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(LSTM(64,\n",
    "#               activation='tanh', \n",
    "#                recurrent_activation='hard_sigmoid'))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"linear\"))\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='loss', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12504 samples, validate on 3127 samples\n",
      "Epoch 1/20\n",
      "12504/12504 [==============================] - 24s 2ms/sample - loss: 8865.7847 - val_loss: 13457.7411\n",
      "Epoch 2/20\n",
      "12504/12504 [==============================] - 16s 1ms/sample - loss: 8341.6844 - val_loss: 12705.7396\n",
      "Epoch 3/20\n",
      "12504/12504 [==============================] - 16s 1ms/sample - loss: 7835.1877 - val_loss: 11956.5982\n",
      "Epoch 4/20\n",
      "12504/12504 [==============================] - 16s 1ms/sample - loss: 7290.5353 - val_loss: 10964.8836\n",
      "Epoch 5/20\n",
      "12504/12504 [==============================] - 16s 1ms/sample - loss: 6748.7243 - val_loss: 10061.7568\n",
      "Epoch 6/20\n",
      "12504/12504 [==============================] - 16s 1ms/sample - loss: 6174.6847 - val_loss: 11267.4667\n",
      "Epoch 7/20\n",
      "12504/12504 [==============================] - 18s 1ms/sample - loss: 5603.0353 - val_loss: 9574.7522\n",
      "Epoch 8/20\n",
      "12504/12504 [==============================] - 17s 1ms/sample - loss: 5092.7066 - val_loss: 7741.0547\n",
      "Epoch 9/20\n",
      "12504/12504 [==============================] - 18s 1ms/sample - loss: 4612.6583 - val_loss: 7809.6164\n",
      "Epoch 10/20\n",
      "12504/12504 [==============================] - 19s 1ms/sample - loss: 4121.4040 - val_loss: 7262.0347\n",
      "Epoch 11/20\n",
      "12504/12504 [==============================] - 19s 2ms/sample - loss: 3754.8510 - val_loss: 7727.2215\n",
      "Epoch 12/20\n",
      "12504/12504 [==============================] - 18s 1ms/sample - loss: 3330.1988 - val_loss: 6136.3121\n",
      "Epoch 13/20\n",
      "12504/12504 [==============================] - 19s 2ms/sample - loss: 2892.7571 - val_loss: 5834.7096\n",
      "Epoch 14/20\n",
      "12504/12504 [==============================] - 18s 1ms/sample - loss: 2484.1903 - val_loss: 5302.5411\n",
      "Epoch 15/20\n",
      "12504/12504 [==============================] - 17s 1ms/sample - loss: 2114.9405 - val_loss: 4475.8761\n",
      "Epoch 16/20\n",
      "12504/12504 [==============================] - 19s 1ms/sample - loss: 1765.3887 - val_loss: 3963.2863\n",
      "Epoch 17/20\n",
      "12504/12504 [==============================] - 21s 2ms/sample - loss: 1449.1733 - val_loss: 3727.0999\n",
      "Epoch 18/20\n",
      "12504/12504 [==============================] - 18s 1ms/sample - loss: 1155.5892 - val_loss: 3388.1509\n",
      "Epoch 19/20\n",
      "12504/12504 [==============================] - 18s 1ms/sample - loss: 898.3009 - val_loss: 2859.0382\n",
      "Epoch 20/20\n",
      "12504/12504 [==============================] - 19s 1ms/sample - loss: 694.1637 - val_loss: 2565.8883\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 300\n",
    "EPOCHS = 20\n",
    "\n",
    "History = model.fit(xtrain, ytrain,\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1,\n",
    "                    callbacks=[lr_decay, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>68.754123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAE</td>\n",
       "      <td>59.249052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R2</td>\n",
       "      <td>-1.440868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metrics     Linear\n",
       "0    RMSE  68.754123\n",
       "1     MAE  59.249052\n",
       "2      R2  -1.440868"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Metrics': ['RMSE', 'MAE', 'R2'],    \n",
    "              'Linear': [np.sqrt(mean_squared_error(y_pred, ytest)),mean_absolute_error(y_pred, ytest),r2_score(y_pred, ytest)]\n",
    "              })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
